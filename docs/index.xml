<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SDTTTTT's Log</title><link>https://sdttttt.github.io/</link><description>Recent content on SDTTTTT's Log</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2020, SDTTTTT.</copyright><lastBuildDate>Wed, 24 Mar 2021 16:33:21 +0800</lastBuildDate><atom:link href="https://sdttttt.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Log 18</title><link>https://sdttttt.github.io/blog/log-18/</link><pubDate>Wed, 24 Mar 2021 16:33:21 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-18/</guid><description>最近有好消息和坏消息：
坏消息就是工作地点改了，现在每天早上都要做1小时地铁才能到公司，啊啊啊，好想换成里家里近一点的地方锕&amp;hellip;
好消息就是原来工作的地点太挤了，这次终于有了独立的办公桌，有点爽，最近也开始富起来了，该给家里的电脑换外设了。</description></item><item><title>Log 17</title><link>https://sdttttt.github.io/blog/log-17/</link><pubDate>Mon, 22 Mar 2021 11:16:33 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-17/</guid><description>最近工作虽然忙，但是强摸还是能摸出一些时间来，GRC又有了新的需求，要增加GPG的提交签名。
一开始我以为很简单，因为看起来我原本使用的git2-rs这个库提供了签名的实现，有一个commit_sign方法。
实际这个方法里面没有实现签名的生成，没办法只好去开源社区里找找了，issue里有有好心人提供了链接，我大概看了看，
最后把目光转向到了gpgme这个库上，但是这个玩意是一个对FFI的包装库，并不是原生实现，编译的时候需要依赖一些C/C++的链接库。我佛了。
这就意味这在Windows上的运行会出现麻烦。后来又找了别的库，但是都很底层，API文档看的我一脸愣逼。 这个问题，还真的得拖一段时间。
希望有带佬能搞一个Rust原生又方便的GPG签名库. 如果实在没有，我亲自上也不是不行&amp;hellip;emmmm (逃)</description></item><item><title>Log 16</title><link>https://sdttttt.github.io/blog/log-16/</link><pubDate>Tue, 16 Mar 2021 16:52:51 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-16/</guid><description>给Blog换个一个配色, 之前的配色太原生HTML, 丑的我都有点看不下去了&amp;hellip;
新的主题是themes.gohugo.io上随便挑的, 看顺眼就用上了. 讲的就是眼缘.Emm..
其实我还是比较喜欢纯色的主题. 有MACOS感觉的那种emm..</description></item><item><title>Log 15</title><link>https://sdttttt.github.io/blog/log-15/</link><pubDate>Thu, 04 Mar 2021 16:58:54 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-15/</guid><description>好tm忙, 但是又好tm无聊.</description></item><item><title>Log 14</title><link>https://sdttttt.github.io/blog/log-14/</link><pubDate>Tue, 02 Mar 2021 10:36:48 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-14/</guid><description>最近不想让服务器多余的资源吃灰, 就在服务器上做了种, 提供一些下载资源的速度. 不过带宽确实是太小了, 这个玩意总共就1m带宽, 如果边做种我再边用RSS的话, 这个速度我都怀疑这玩意是不是done了?
所以平时白天做种的速度只能限制再100KB/s以下, 不如RSS的速度真的太感人. 晚上的话, 龟速模式就会解除, 做种速度能提升大概3-4倍的样子.
如果有机会还是想白嫖带宽大一点的服务器锕.</description></item><item><title>RSS 好耶!</title><link>https://sdttttt.github.io/blog/new-rss/</link><pubDate>Sat, 20 Feb 2021 11:13:45 +0800</pubDate><guid>https://sdttttt.github.io/blog/new-rss/</guid><description>最近迷上了RSS这种获取信息的方式, 平时访问多个网站来获取信息的方式实属低效率, 而且太碎了, 俺这种老年人就经常忘记.
RSS: 简易信息聚合（也叫聚合内容）是一种基于XML标准，在互联网上被广泛采用的内容包装和投递协议。RSS(Really Simple Syndication)是一种描述和同步网站内容的格式，是使用最广泛的XML应用。RSS搭建了信息迅速传播的一个技术平台，使得每个人都成为潜在的信息提供者。发布一个RSS文件后，这个RSS Feed中包含的信息就能直接被其他站点调用，而且由于这些数据都是标准的XML格式，所以也能在其他的终端和服务中使用，是一种描述和同步网站内容的格式。
目前使用RSS有一个很阴霸的东西, 叫做RSSHub, 这个玩意能很好解决你找RSS订阅的麻烦.
RSSHub 是一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源。RSSHub 借助于开源社区的力量快速发展中，目前已适配数百家网站的上千项内容.
不过这玩意是一个服务器软件, 需要单独部署的. 官方提供的demo有很大一部分的RSS Feed都是无效的. 这两天正好自建了一个RSSHub, 在这里.
如果有需要可以使用这个地址来代替官方提供的demo. 至少一年内都不会失效🐶
小声BB: 实际上我的blog也是有rss的, 你能找到么?</description></item><item><title>记录一次Gradle构建的困难</title><link>https://sdttttt.github.io/blog/gradle-build-for-idiotc4t/</link><pubDate>Fri, 05 Feb 2021 10:57:31 +0800</pubDate><guid>https://sdttttt.github.io/blog/gradle-build-for-idiotc4t/</guid><description>受@idiotc4t所托, 我拿到了一个Java项目, 目的是要把这玩意编译出来, 最初我还以为和以前的Java项目类似, 只要mvn build 就能一了百了, 没想到这次拿到的是一个使用gradle构建的项目.
gradle的出现比maven晚, 它们都是用来构建运行在JVM上的应用使用的, gradle可以使用编程语言来自定义你的构建流程, 类似C的makefile(这个比喻不太好其实), 或者是JavaScript的gulp. gradle解决了maven的一些特点, 比如xml的配置繁琐, 看着就头大, 以及构建步骤的灵活控制. 总之很牛逼就是了, 也比较难上手.
由于我以前使用过一段时间的gradle, 所以我知道用gradle打jar包的困难. (gradle这个工具通常都是给Android开发者用的, 默认没有提供打成Jar包的选项, 所以打出来什么包, 得看缘分.)
当我运行gradle build后, 光速构建完成, 我定神一看, 没有工程文件目录, 倒是有一个jar包 ,这个jar包就14KB, 好家伙, 肯定没构建成功. (正常的java程序绝对不会这么小, 一般肯定是1MB以上) 输入java -jar一看, 果然:
...jar: 没有主清单属性 总之我在网上查了半天都没发现解决方法. 最后把目光转向代码, 最后发现在代码中都没有声明包路径&amp;hellip;
(嘶&amp;hellip;.这厮在README里是怎么打包的???我怀疑有这B留了一手)
最后用宇宙第一IDE(IDEA)重构了整个包的代码, 补上了包路径. 再次尝试gradle build,终于看到了工程文件.
总之, 还好老子技高一筹.
写完了, 摸了.</description></item><item><title>节流与防抖</title><link>https://sdttttt.github.io/blog/js-1/</link><pubDate>Mon, 18 Jan 2021 16:49:35 +0800</pubDate><guid>https://sdttttt.github.io/blog/js-1/</guid><description>闲来无事在网上翻一些关于 Javascript 的一些搞基技巧，就发现了节流与防抖这两种设计模式。
上个星期在编写搜索框的时候就已经写过类似的代码 （搜索框输入关键词会实时去服务器上搜索，考虑到服务器压力就把代码加了限制，每 500ms 最多搜索一次，实际上这就是类似防抖的设计，只是我还不知道这个叫防抖&amp;hellip;）
下面是搜索框的限制代码：
watch(searchText, (newVal) =&amp;gt; { clearTimeout(searchTimer); searchTimer = setTimeout( () =&amp;gt; //...需要限制的逻辑 ), 500 ); }); 原理非常简单，通过定时器实现，一旦现有状态改变就说明有新的输入，然后清除老的定时器，新设置定时器。
今天在网上冲浪又学到了一种新的设计：节流
直接看代码吧：
watch(searchText, (newVal) =&amp;gt; { if(isStop) { return } isStop = true; setTimeout( () =&amp;gt; { //...需要限制的逻辑 isStop = false } ), 500 ); emmm，一开始看了半天，实际上看懂之后节流比防抖更加简单 （好吧，看了几遍其实发现差不多）
原理还是一样简单，计数器结束将标志位设置为 false，这样新来的计时器就能通过，如果没到限制时间就进入这个函数会被标志位拦住，直接返回。
节流主要作用就是限制执行频率。
硬要说防抖和节流的区别。。。emm我也说不上来，看应用场景吧。</description></item><item><title>Composition Api</title><link>https://sdttttt.github.io/blog/composition-api/</link><pubDate>Thu, 14 Jan 2021 10:29:36 +0800</pubDate><guid>https://sdttttt.github.io/blog/composition-api/</guid><description>最近一直在写 Vue, 在公司的项目里使用的是Composition Api + Vue2 的组合. (因为公司里考虑到同事的技能树, 没有用vue3和Typescipt).
CA 是 Vue3 追加的全新 API. 用到 Vue2 里可能有点怪怪的.
不过 CA 是以 Vue-Plugin 的方式提供的 API, 所以使用起来非常方便. 同时也鼓励更多人使用这个API.
首先是关于这个API的使用方式, 以前的代码需要将方法卸载method区块中, 每个变量和方法之间的关系很模糊暧昧.
需要开发者自己去找关于每个方法和变量之间的关系, 用CA之后可以写出类似ReactHook风格的代码.
// OA (Option API 原版的API是这样称呼的) { data: { count: 1 }, methods: { sub(num: number) { // ... }, add(num: number) { // ... } } } // CA const count = ref(1); const { add, sub } = useCount(); add(1); sub(2); function useCount(count: Ref&amp;lt;number&amp;gt;) { function sub(num: number) { // .</description></item><item><title>Log 13</title><link>https://sdttttt.github.io/blog/log-13/</link><pubDate>Mon, 21 Dec 2020 09:05:08 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-13/</guid><description>粗且谈一下关于新的主机的想法.
i5 10400F 这块U不带核显, 这倒是无所谓, 是i5里目前第一块6core12thread的U. 性能接近i7 8700. CPU实际上无所谓.
24G RAM 24G也是我想过之后才选择的内存大小, 32嫌大, 16嫌小, 只能这样了.
W240 散热是一个W240的水冷, 只有一个风扇. 虽然是W240, 但感觉很可能是个丐中丐.
ASUS B460-K 丐中丐主板, 用i5 10400F这U还是没有问题的. 这主板设计也有问题. SATA接口在显卡散热口的下面就离谱.
NVME M.2 250G 固态硬盘, 就这样吧, 速度倒是无所谓, 容量小了点, 导致我后面又追加了一个1T的PMR.
ASUS TUF RX5600XT 6G EVO-GAMING 嘶&amp;hellip;这显卡就比较尴尬了. 先说参数. 频率比公版高一点. TUF是个丐版, 三风扇, 其他没有问题的. 性能基本上和2060并肩,甚至更高.能超到2060S的水平. 这玩意为什么尴尬呢, 因为这块卡稍微加一两百就能到5700, 屁股后面又是RX590. 说这玩意是智商检测卡也没什么问题. 最后这块卡打全境2 全高 2560*1080居然不能稳定60FPS??? 太蒂蒂了
周末基本上就是打游戏了. 还有追加了个硬盘. 硬盘的SATA线穿过显卡风扇. 看起来十分诡异. 这个SATA接口就不能长外面么???</description></item><item><title>Log 12</title><link>https://sdttttt.github.io/blog/log-12/</link><pubDate>Fri, 18 Dec 2020 12:22:28 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-12/</guid><description>这两天有个接口测试的前端项目终于开始动土了，我还是一如既往的写前端呢。谁让我TM是高贵的全栈工程师（狗头
新的台式主机也到了， 配置撑个2年不是什么大问题。 双休日总算可以畅爽的打游戏了， 还有希望明天的硬盘和音响能快点到。打游戏没有声音可是大忌锕。</description></item><item><title>Log 11</title><link>https://sdttttt.github.io/blog/log-11/</link><pubDate>Tue, 01 Dec 2020 10:04:34 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-11/</guid><description>昨天发布了GRC的0.9.2版本, 这个版本更新说实话比较水. 追加的功能有参数指定配置文件.还有一些小问题的修复, 就没了emm
下次GRC追加功能应该会在v1.0.0, 终于要到正式版本了. 如果有人有更好的想法得和我说啊啊啊!!~~ 我都想不好加什么功能比较好.</description></item><item><title>Log 10</title><link>https://sdttttt.github.io/blog/log-10/</link><pubDate>Wed, 25 Nov 2020 11:25:47 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-10/</guid><description>昨天一大早就跑去余杭, 去新园区面试. 真的挺麻烦的. 希望这种事越少越好.
害得我昨天都没有commit.</description></item><item><title>Sql Optimize</title><link>https://sdttttt.github.io/blog/sql-optimize/</link><pubDate>Thu, 19 Nov 2020 13:10:52 +0800</pubDate><guid>https://sdttttt.github.io/blog/sql-optimize/</guid><description>本文主要讲关于SELECT语句的优化问题. 会涉及到一些关于表索引的知识.
性能 很简单, 你每建立一个索引, 数据库就会根据索引类型，帮你建立一个索引数据结构（B+树非常常用）.
NOTE:B+树
B+树对范围查询和直接查询都很在行. 直接查询的时间复杂度均为O(log), 也就是用的二分法, 具体为什么就去看B+树的数据结构, 在看B+树之前最好先看B树, 不然东西太多消化不了.
不过每次插入数据和删除数据就需要重构索引树的结构, 滥用索引反而会降低写入效率.
设计 索引有好几种, 最常用的有:
主键索引: 比如用户表的ID字段 唯一索引: 比如不可重复的用户名 组合索引: 需要经常被一起查询的字段, 比如用户名, 密码 普通索引: 这个怎么用就仁者见仁智者见智了. 索引一经创建不能修改，如果要修改索引，只能删除重建. 具体怎么创建就baidu吧。
如果要查看一张表的索引, 如下:
mysql&amp;gt; SHOW INDEX FROM users; +-------+------------+-----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +-------+------------+-----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | users | 0 | PRIMARY | 1 | id | A | 9847 | NULL | NULL | | BTREE | | | | users | 0 | id_UNIQUE | 1 | id | A | 9847 | NULL | NULL | | BTREE | | | | users | 0 | username | 1 | username | A | 9847 | NULL | NULL | | BTREE | | | +-------+------------+-----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 3 rows in set (0.</description></item><item><title>GRC 5</title><link>https://sdttttt.github.io/blog/grc-5/</link><pubDate>Tue, 17 Nov 2020 15:08:13 +0800</pubDate><guid>https://sdttttt.github.io/blog/grc-5/</guid><description>很有趣, 上个星期有人在GRC中和我提了一个问题, GIT很多操作是要使用环境变量来控制.
我平时根本不使用环境变量来控制GIT, 这个特性可能会在以后支持吧.</description></item><item><title>Go的map的个什么结构</title><link>https://sdttttt.github.io/blog/go-map/</link><pubDate>Fri, 13 Nov 2020 15:31:53 +0800</pubDate><guid>https://sdttttt.github.io/blog/go-map/</guid><description>实际上Go的map和Java7之前的HashMap, 非常相似。都是Array + LinkedTable的结构。
结构 map数据结构由runtime/map.go/hmap定义:
type hmap struct { count int // 当前保存的元素个数 ... B uint8 // 指示bucket数组的大小 ... buckets unsafe.Pointer // bucket数组指针，数组的大小为2^B ... } bucket数据结构由runtime/map.go/bmap定义：
type bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 这里使用的数组对齐方式来存放数据。overflow指向下一个bucket.
工作流程 首先通过key计算Hash值，通过Hash的低位，计算出该元素需要存放在buckets中的哪一个bucket. 如果Hash冲突，也就是当前bucket已经有人进去了。那么就使用该bucket的overflow指向自己的bucket.
查找元素也是大同小异。</description></item><item><title>GRC 4</title><link>https://sdttttt.github.io/blog/grc-4/</link><pubDate>Thu, 12 Nov 2020 14:07:47 +0800</pubDate><guid>https://sdttttt.github.io/blog/grc-4/</guid><description>啊哈, 我的新键盘已经到了, 这周周末(11.13-11.15)我会尽快修复目前GRC中的一些问题:
#25 Did not check type. #28 [Feature request] Create a template gcr.toml when the install is made with cargo #30 env GIT_AUTHOR_NAME is not used 希望有更多人使用GRC.</description></item><item><title>Impl and Dyn on Rust</title><link>https://sdttttt.github.io/blog/rust-impl-and-dyn/</link><pubDate>Thu, 12 Nov 2020 09:46:53 +0800</pubDate><guid>https://sdttttt.github.io/blog/rust-impl-and-dyn/</guid><description>我们先来看这样一段代码:
impl View for Button { ... } impl View for Text { ... } 我们看到Button和Text都实现了View属性, 抽象是一种不错的设计程序的方法, 帮助我们透明化的使用外部提供的API. 然后我们可能会下意识的写出下面的代码:
/// 这种代码实际上会让人感到疑惑. View究竟是个特性还是一个对象. /// 这里的View是一个类型, 所以我们需要写成 `impl View`. /// 不过`impl View` 不能用于多个trait实现的返回. 但是可以作为入参. pub fn something() -&amp;gt; View { if ... { Button { ... } } else { Text { ... } } } 这段代码无法通过编译, 原因就是返回值View需要在编译器确认大小. 我们需要把它装成一个胖指针.
pub fn something() -&amp;gt; Box&amp;lt;View&amp;gt; {...} 嗯,这样就好很多. 但是编译器会爆种, 提出一个警告, 希望你把Box&amp;lt;View&amp;gt;改为Box&amp;lt;dyn View&amp;gt;.
这又是什么意思?
dyn 是动态的缩写, 意义其实很明显.</description></item><item><title>Redis Compile</title><link>https://sdttttt.github.io/blog/redis-compile/</link><pubDate>Wed, 11 Nov 2020 16:43:06 +0800</pubDate><guid>https://sdttttt.github.io/blog/redis-compile/</guid><description>也不知道我发了什么疯, 在windows上编译了一遍redis. 事实上我找到的windows上最新的redis版本是3.
这个版本以及相当老了. 目前最新的redis是在6. 我不想功能相差过大,就重新在windows上编译了一次.
中间捣鼓了很久. 由于redis是在unix环境上开发的, windows上编译还是很麻烦. 首先试了cygwin这个unix模拟环境可惜编译失败了. 后面我下载了msys2这个unix的工具套件. 这次很顺利. redis6的包我就放在这里, 需要可以下载.</description></item><item><title>Log 9</title><link>https://sdttttt.github.io/blog/log-9/</link><pubDate>Wed, 11 Nov 2020 14:04:54 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-9/</guid><description>上周周五学习了一个新的玩意，一个自动化测试类库（Selenium），作用也比较简单，在浏览器的网页上模拟鼠标和键盘输入操作。是个没啥难度也没啥营养的东西。就像换了个语言写Javascript一样。
出乎意料的是这周的开头居然有歪果仁在我的GRC上提出了一些问题，我还以为这个项目会孤独终老，看起来还是有人在使用的。正好，趁着11.11换了个显示屏和键盘，等发工资就再买个PC主机，我就趁这段时间把目前GRC存在的问题解决了。
最近也打算学习一下操作系统的知识，希望这个月顺利。</description></item><item><title>GRC 3</title><link>https://sdttttt.github.io/blog/grc-3/</link><pubDate>Tue, 03 Nov 2020 14:28:39 +0800</pubDate><guid>https://sdttttt.github.io/blog/grc-3/</guid><description>上周末算是把GRC扩展的部分开发完成了， 最开始写的时候没有遇到什么特别大的困难， 不禁感叹，我写Rust越来越顺手了已经.
结果到星期六准备把几个模块接起来的时候， 发现出现了变量生命周期的问题，我还特地去找人问， 但根本没啥人鸟我。没办法，最后算是有意无意之间发现了解决的方法&amp;hellip;
最后在星期六晚上总算是编写完成了已经，星期天的时候发布了。 可惜这几天的下载量都愁云惨淡&amp;hellip;</description></item><item><title>Log 8</title><link>https://sdttttt.github.io/blog/log-8/</link><pubDate>Thu, 29 Oct 2020 09:04:14 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-8/</guid><description>每天上班, 先骑15分钟自行车到地铁再做20多分钟地铁, 针不戳.
感觉体能下降的厉害.
今天在博客仓库了增加了hugo模块。 以后看起来跟换主题会方便很多。 但是为啥有go.mod文件。这又不是一个go项目&amp;hellip;</description></item><item><title>Log 7</title><link>https://sdttttt.github.io/blog/log-7/</link><pubDate>Wed, 28 Oct 2020 09:54:22 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-7/</guid><description>尝试优化一下文章创建的脚本.</description></item><item><title>Log 6</title><link>https://sdttttt.github.io/blog/log-6/</link><pubDate>Tue, 27 Oct 2020 17:24:55 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-6/</guid><description>最近仔细反思了一下, 还是去研究一些什么东西. sraft已经写的我头都大了. 我打算最近一段时间不再在Github上编写代码了.
一方面是没有什么东西打得起我的兴趣, 另一方面还是觉得自己没有真正擅长的方面, 研究分布式系统这么长时间, 进展真的很慢, 一是我平时很懒, 不喜欢搭复杂的环境, 二是单纯的分布式方面的知识没有什么软用. 需要结合其他方面.
潜了潜了. (当然博客还是会写www)</description></item><item><title>Cache Algorithm</title><link>https://sdttttt.github.io/blog/cache-algorithm/</link><pubDate>Mon, 26 Oct 2020 11:03:33 +0800</pubDate><guid>https://sdttttt.github.io/blog/cache-algorithm/</guid><description>本文主要讲的是目前存在的几种缓存算法, 没错, 我又来误人子弟了.
内容会围绕近几年比较流行的LFU, LRU, 还有W-TinyLRU这么三种缓存算法来讲, 尽量使用最简练的文本.
LFU 近期最少使用算法，即LFU算法（Least Frequently Used algorithm）。 这种算法会淘汰近期最少访问的缓存, 仔细分析一下, 没错，这是一种非常合理的算法，因为到目前为止最少使用的页面， 很可能也是将来最少访问的页面。 该算法既充分利用了内存中缓存调度情况的历史信息，又正确反映了程序的局部性。
但是，这种算法的开销极其高, 为了记录每个缓存的使用情况, 你不得不为每一个缓存增加一个很大的计数器, 每次到达临界点, 我们还需要找到所有计数器中最少的缓存, 淘汰它.
核心思想：如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小. 通常我们会这么去实现:
外部结构为Array, 存储元素为KV. K: 该缓存访问次数. V: 缓存本身. 数组按照K排序. 每次缓存大小即将临界, 淘汰K最小的缓存.
顺便一提 Window-LFU 它是LFU算法的改良版. LFU中缓存的访问次数记录的时间范围为整个程序的生命周期, 在Window-LFU中只对特定范围的访问次数进行淘汰. (比如最近10次访问的缓存.)
LRU 最久没有使用算法，即LRU算法（Least Recently Used algorithm）。 这种算法把近期最久没有被访问过的页面作为被替换的页面。 它把LFU算法中要记录数量上的&amp;quot;多&amp;quot;与&amp;quot;少&amp;quot;简化成判断&amp;quot;有&amp;quot;与&amp;quot;无&amp;quot;，因此，实现起来比较容易。
核心思想：如果在一段时间内长时间不访问的页面将来也不会访问. 实现很简单:
假设我们的缓存容量大小为2, 最多缓存2个元素. 下面是缓存的访问顺序.
1 2 2 3
第一次: [1]
第二次: [2, 1]
第三次: [2, 1]</description></item><item><title>Log 5</title><link>https://sdttttt.github.io/blog/log-5/</link><pubDate>Fri, 23 Oct 2020 16:44:07 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-5/</guid><description>今天写了一天的sraft. 本来是自信满满，但是有些地方的设计真的让我焦头烂额.
今天把sraft的rpc的网络通信部分换成了长连接。 但是写到节点发现的部分又有问题来了，我没有写关于处理节点发现之类的模块， 至今都是按照raft论文上的基础理论来实现的。
这一块又要怎么设计呢&amp;hellip; 果然有些地方写的还是太复杂了么.</description></item><item><title>Log 4</title><link>https://sdttttt.github.io/blog/log-4/</link><pubDate>Thu, 22 Oct 2020 09:26:05 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-4/</guid><description>昨天算是完成了第一个前端上需求.来讲讲成果吧. (其实根本无关紧要)
看了SVN记录,整个项目第一次提交是在2018年. (立项的时间感觉肯定更早)
整体技术使用的基本时原生JS(没有ES6) + Jquery. 项目代码风格凌乱. 肯定有好几个人接手过了.
每个页面还不是HTML&amp;hellip;是nm的JSP.(所以我才觉得应该不是2018年立项的) 所以整个项目都是在Tomcat上运行的.正常来说都是写成HTML然后跑在Nginx上.
这次的需求就是在原来的页面上加一个新的按钮并且完善整个页面. 我看来那个页面的其他标签.用的基本是绝对定位布局..惊了
这次我基本把原生JS完全复习了一遍. 我不太喜欢使用Jquery.因为感觉语法很奇怪, 可读性很差.
还学到了一个新的库(GoJS)用来画图的.这个库入门很简单,但是要高度自定义使用还是有些困难的.
唉, 我到底啥时候才能写后端嘞.</description></item><item><title>Log 3</title><link>https://sdttttt.github.io/blog/log-3/</link><pubDate>Wed, 21 Oct 2020 08:55:36 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-3/</guid><description>细心的人可能注意到我这几天都在写JS, 因为这边的公司人手其实缺乏很严重, 很多都是做后端的, 而且后端并不是全部Java, 有相当部分是Python写的.
我在大学期间为了选择以后的WEB方向, 一狠心把当时比较前沿的WEB技术全部学了一遍, 包括前端的一些框架, 最后选择了WEB后端, 语言为Go, 或者Java. 也算半个全栈吧.
这个公司正好是发挥了我所有的技能..不过这边的JS大部分都是原生的, 我比较习惯用ES6的写法.</description></item><item><title>RocketMQ 3.3.4 Broker</title><link>https://sdttttt.github.io/blog/rocketmq-comments/</link><pubDate>Tue, 13 Oct 2020 16:56:11 +0800</pubDate><guid>https://sdttttt.github.io/blog/rocketmq-comments/</guid><description>差不多可以看消息队列的源码了。 在下从gitee上找到了rocketmq的早期版本（3.2.2）， 坏消息是这个2014年的项目里没有单元测试极少, 调试会比较困难. 好消息是这个时候的RocketMQ还没开源多久，里面有很多中文注释。看起来会很舒服。
我们从Broker开始涂鸦。关于RocketMQ中每个角色的作用这里不再陈述：
先从初始化开始：
public static void main(String[] args) { start(createBrokerController(args)); } rocketmq是从commandline启动的，createBrokerController函数比较长， 会有很多额外的逻辑干扰你，我这里直接说重点：
读取环境变量，没有就用默认值。 解析命令行参数。 初始化配置类。 打印默认配置内容。 检查NameServer地址设置是否正确。 检查broker的类型（master，slave） 初始化日志配置类。 再次打印。 初始化服务控制对象. 最后增加一个关闭Broker时触发的hook. 服务控制对象： Broker各个服务控制器，包括存储层配置，配置文件版本号，消费进度存储，Consumer连接、订阅关系管理等等。
以上就是createBrokerController的内容，函数虽然长，但是并不复杂。
下面为start函数的内容, 在main中的start函数实际上是去委托了BrokerController去执行.
public void start() throws Exception { // 启动Broker的各层服务 if (this.messageStore != null) { this.messageStore.start(); } if (this.remotingServer != null) { this.remotingServer.start(); } if (this.brokerOuterAPI != null) { this.brokerOuterAPI.start(); } if (this.pullRequestHoldService != null) { this.</description></item><item><title>日志</title><link>https://sdttttt.github.io/blog/log-2/</link><pubDate>Sun, 11 Oct 2020 14:45:23 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-2/</guid><description>昨天骑自行车下班回来后荨麻疹又犯了, 实在是比较难受, 今天算是去了趟皮肤病医院.
算是配了点药. 希望能好一点.</description></item><item><title>Sraft (三)</title><link>https://sdttttt.github.io/blog/sraft-3/</link><pubDate>Fri, 09 Oct 2020 10:52:24 +0800</pubDate><guid>https://sdttttt.github.io/blog/sraft-3/</guid><description>经过几天思考, 我决定稍微重新分配一下各个模块的密度.
RaftKernel中的Solt为本次的重点.对RaftKernel来说Solt为一个黑盒.Solt对外处理所有事件,但是不暴露实现. 内部的状态机转化也对RaftKernel进行隐藏.RaftKernel只要接受外界AE, 交给Solt, Solt反馈相应的事件, RaftKernel进行处理.
挖藕, 希望这次有效.</description></item><item><title>Essays</title><link>https://sdttttt.github.io/blog/essays/</link><pubDate>Tue, 06 Oct 2020 12:34:31 +0800</pubDate><guid>https://sdttttt.github.io/blog/essays/</guid><description>前几天去朋友那边玩了一趟, 事实上并没有什么好玩的. 这几天什么也没做. sraft也没有什么进展.
我又重新对Ruby on Rails 感兴趣了.但是没有一个很好的环境写这个东西.还是算了.
还是想想下一个项目写什么比较好.</description></item><item><title>GRC (二)</title><link>https://sdttttt.github.io/blog/grc-2/</link><pubDate>Thu, 01 Oct 2020 15:24:27 +0800</pubDate><guid>https://sdttttt.github.io/blog/grc-2/</guid><description>昨天姑且算是完成了GRC的开发. push这个命令不是很想加,想了一下也没有必要.
GRC的0.8.0版本昨天算是发布了, 应该也算是头一次正经的用Rust来开发软件.
在crate.io上看起来有100的安装了. 不知道他们脸上是什么表情 wwww
希望GRC能给他们带去方便吧.
当然, GRC的终点还没到. 我会一直使用这个工具. 碰到BUG或者有新想法肯定会去更新.况且现在连1.0.0版本都还没到.
接下来主要工作会专注到学习加密算法,和sraft的开发上.
&amp;hellip;sraft一直都没有什么好的想法啊&amp;hellip;</description></item><item><title>GRC (一)</title><link>https://sdttttt.github.io/blog/grc-1/</link><pubDate>Sat, 26 Sep 2020 14:49:17 +0800</pubDate><guid>https://sdttttt.github.io/blog/grc-1/</guid><description>ooo! 一个不错的消息.
目前GRC的commit规范的功能已经完全实现了. 之前还说要几个星期, 看来比我想得要快很多 👴勤勉 基本上已经和git-cz有着完全一致的功能. 我也已经把GRC发布在了crates.io网站上. 在crates.io上搜索grc就能看到. 同时我也在v2ex上写了关于GRC的文章.
开发也会继续进行, GRC会在以后为你提供更方便的功能. 我也期待有人能参与到这个项目中来.
希望GRC能帮助更多人.</description></item><item><title>sraft (二)</title><link>https://sdttttt.github.io/blog/sraft-2/</link><pubDate>Tue, 22 Sep 2020 12:08:44 +0800</pubDate><guid>https://sdttttt.github.io/blog/sraft-2/</guid><description>昨天草草的完成了通信协议适配器, 至少能做到自由切换协议, 纵看整个编程模型还是有缺陷, StateMachine的内部结构比我想的要复杂的多, 多个状态实现的切换,以及对一些内部事件的触发. StateMachine模块的密度和其他模块完全不同. 反而RaftKernel存在的意义却减小了.
经过昨天晚上和今早的考虑, 我决定将StateMachine作为一个Slot,接入到RaftKernel中去, RaftKernel现在同时也是状态机本身, Slot是可变的, 可以有Leader, Follower, Candidate三种插槽,每个Slot都有不同的扩展字段, 比如Leader会需要登记每个Node的同步日志的深度以及状态. 并且每个Slot都有自己的事件处理实现.
没想到第一天开发结束就会遇到麻烦, 看来sraft以后的苦难还不少&amp;hellip;</description></item><item><title>Sraft (一)</title><link>https://sdttttt.github.io/blog/sraft-1/</link><pubDate>Mon, 21 Sep 2020 11:29:51 +0800</pubDate><guid>https://sdttttt.github.io/blog/sraft-1/</guid><description>今天开始算是正式编写Sraft这个库, 开发的原因有两个:
我需要通过这次开发来熟悉Raft这个协议.(以后面试或者和人攀谈也更有底气) 我的微服务框架的服务中心需要一个能达成分布式一致性的功能. 语言采用的是Go, 目前的编程模型大概也完成了, 下面我来介绍:
本人喜欢简单并且高效的设计, 对于设计复杂难以实现的东西会感到不适(脑子不够用),
Raft Kernel 整个编程模型会有比较多的模块, 整体采用的是微核架构, Raft Kernel会协调各个模块之间的工作.
模块之间的通信由Raft Kernel来完成. 通信方式采用Channel异步非阻塞的形式.
Exchange Network 外部通信从这里进入, 由Exchange Network将通信内容封装为事件, 发送给Raft Kernel.
或者Raft Kernel传递事件给Exchange Network, 再由Exchange Network执行外部通信.
State Machine Raft协议的核心实现, 状态机会在Leader, Follower, Candidate三种角色之间自动切换, 每一角色处理的事件都是一样的, 但是具体过程是不一样的. (这个部分的密度会比较大)
Data Log Synchronizer 负责同步数据的模块, 采用的是日志提交形式.
以上的我目前已经构思出的编程模型, 但是为暂定. 实际的编写模型肯定会有少许修改.
PROJECT: github.com/sdttttt/sraft</description></item><item><title>About Gcr</title><link>https://sdttttt.github.io/blog/about-gcr/</link><pubDate>Sun, 20 Sep 2020 13:20:06 +0800</pubDate><guid>https://sdttttt.github.io/blog/about-gcr/</guid><description>十多天前, 我创建了GCR这个项目, 原因比较纯粹, 我是个命令行工具爱好者, 我认为命令行能带来更好的工作效率以及收益, 我平时编码, 也是遵守Git提交规范的, 使用Node.js平台上的git-cz工具来格式化我的提交信息, 不过由于它属于Node.js这个平台, 不可避免, 你需要安装Node.js的runtime环境.
我想要一种更加方面快速的工具, 所以我建立了GCR这个项目, 它是使用Rust编写的, 不需要安装任何环境, 比起Node, 它会更快, 而且保留了跨平台的特性. 在GCR中我还会加入一些比较个性化的元素. GCR看起来可能会是一个更好用的Git?.
这个项目可能还需要几个星期的时间, 请期待吧.</description></item><item><title>FAQ</title><link>https://sdttttt.github.io/blog/faq/</link><pubDate>Sat, 19 Sep 2020 20:15:53 +0800</pubDate><guid>https://sdttttt.github.io/blog/faq/</guid><description>以前一些小白经常问我的问题.
Q: 我想自己建立一个网站, 我应该使用什么技术?
A: Ruby on Rails.
ROR是一款老牌的WEBMVC框架, 到现在有10多年的历史了. 在中国, ROR使用的并不多, 这并不能说明它不优秀, ROR拥有非常多的功能模块, 几乎没有ROR做不到的. 论开发效率,ROR绝对能满足你, Ruby这个语言, 如果你有去学过, 会发现他的语法非常的随意. 自己造一个语法Ruby都能支持, 我认为, Ruby是在所有语言中开发体验最好的语言. 良好的开发体验加上优秀的开发效率, ROR是值得你去使用的.
Q: 我想写一点小工具, 我应该用什么语言?
A: Python.</description></item><item><title>日志</title><link>https://sdttttt.github.io/blog/log-1/</link><pubDate>Sat, 19 Sep 2020 11:06:17 +0800</pubDate><guid>https://sdttttt.github.io/blog/log-1/</guid><description>目前还是个5月份刚毕业的应届生, 今年还是撞到了疫情这个时间口上, 工作真是相当的难找, 6月到7月的样子, 我去尝试去考驾照, 目前还在科目二这边卡着, 中间有空也是各种找单位去面试.
比较幸运, 我在8月初的时候收到了来自安恒信息的面试通知, 他们是一家上市公司, 规模也不小, 我也是被别人内推才有这个面试资格的, 面试一共三轮, 前两轮技术面试, 最后一轮综合面试, 第一轮技术面试大概就是问了我一些JVM原理, 以及编码思路, 还有一些我比较擅长的分布式存储的问题. 第一轮过的呢也还算惊险. 第二轮是在几天后, 问的内容基本上是一些JDK源码, 数据结构, 还有一些框架问题.我回答的还算是流畅, 也算是过了.可惜,最后一轮面试之前,因为安恒不招收985,211以外的应届生, 所以我被淘汰了.
后面每天在晚上投简历, 大概在一个月后, 又有新的面试来了, 一家叫做郦鸣科技的公司, 面试官问的都是一些业务处理逻辑, 身为应届生的我也是吃了亏, 因为我根本没有实际的工作经验. 不过我还是以试用生的身份进去了.
新人入职第一天就是先把公司项目的代码过一边, 看了他们公司的代码之后, 说实话, 我非常失望, 复杂的对象关系结构, 长冗的控制器函数, 以及空空如也的test文件夹, 我不知道他们的项目能维护多长时间, 可能是我的想法太极端了, 大学时的我就开始受到马丁福勒的软件设计思想的影响, 对维护性差的代码变得敏感起来. 我边读他们的代码, 边重构着. 就这样过了一个星期.
在这周里, 我还收到了来自电信和一家电子交易公司的面试通知, 我很高兴, 因为我对现在的工作并不感到满足, 在周五, 我请了假, 去面试, 电信这边很顺利, 面试官和我说, 他喜欢我的开源项目, 并且对我的CICD技术感兴趣, 而且他也不关心我的学历, 我真的很高兴.不过在录用之前,面试官说得先和上级汇报, 因为录不录用不是他能决定的.
下午, 我去了那家电子交易公司面试, 不过应届生在他们公司面试之前得先做试卷, 内容是关于Java的, 我有点吃惊, 不过我也发现了, 对于一些java代码的运行细节我还了解的不够清楚, 在这里又发现了自己的缺点, 我感到很满足. 试卷完成后, 就是面谈了, 面试官看起来接近30岁, 他先问了我的开源项目的问题, 接着是一些Java基础的问题, 最后又考了考我的业务能力, 他出了一个秒杀题, 我回答的并不算好, 应该只答对了一半.</description></item><item><title>MyBatis 源码分析</title><link>https://sdttttt.github.io/blog/mybatissourcecode/</link><pubDate>Thu, 10 Sep 2020 22:15:42 +0800</pubDate><guid>https://sdttttt.github.io/blog/mybatissourcecode/</guid><description>其实很早就想写一篇 iBatis 的源码分析了, 不过有段时间去学习 Go 了, Java 就放下了, 最近 重新捡起 Java 就把以前没填的坑,填一下.
Init 现在开始正片.
首先是 iBatis 的初始化工作.我们看下面的代码:
// `BlogDataSourceFactory`的主要作用: 通过你的配置文件, 初始化一个DataSource DataSource dataSource = BlogDataSourceFactory.getBlogDataSource(); // JdbcTransactionFactory一个New就能得到, 没什么依赖条件 TransactionFactory transactionFactory = new JdbcTransactionFactory(); // Environment要你交出数据源和事务工厂还有你的环境是开发还是生产 Environment environment = new Environment(&amp;#34;development&amp;#34;, transactionFactory, dataSource); // Configuration有基本上你所有的配置 Configuration configuration = new Configuration(environment); // 添加你的mapper到配置列表中, 等会我们去分析它 configuration.addMapper(BlogMapper.class); // 通过你的配置类,让我们初始化一个SqlSessionFactory! 我们终于进入正题了!! // 可能你觉得很快... 其实本人在这里面分析还是花了很长时间 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); 好, 上文有说configuration.addMapper(BlogMapper.class)这个方法, 现在我们来分析一下它.
// 这个是Configuration中的方法, 它实际上是委托mapperRegistry去执行 public &amp;lt;T&amp;gt; void addMapper(Class&amp;lt;T&amp;gt; type) { mapperRegistry.</description></item><item><title>GoSyncPool</title><link>https://sdttttt.github.io/blog/gosyncpool/</link><pubDate>Thu, 03 Sep 2020 17:06:04 +0800</pubDate><guid>https://sdttttt.github.io/blog/gosyncpool/</guid><description>今天在看Sentinel-golang源码的时候发现sentinel在内部使用了sync.Pool该结构体.看到Sync和Pool的我第一反应想到应该是线程池之类的东西.在实际看过原理之后发现并不是这样的.
sync.Pool 的目的是为了利用对象的复用来减小GC压力.但是开销比较高.要斟酌使用.
Pool和golang的GMP协程模型的关系比较大. sync.Pool对每一个P(系统线程)都分配了一个本地池.
本地池中有2个属性，分别是private和share。 private只能被当前P访问，share可以被不同的P访问.
在执行Get or Put的时候.会对应当前执行P的本地池.
Get 尝试从本地P对应的那个本地池中获取一个对象值, 并从本地池冲删除该值。 如果获取失败，那么从共享池中获取, 并从共享队列中删除该值。 如果获取失败，那么从其他P的共享池中偷一个过来，并删除共享池中的该值(p.getSlow())。 如果仍然失败，那么直接通过New()分配一个返回值，注意这个分配的值不会被放入池中。New()返回用户注册的New函数的值，如果用户未注册New，那么返回nil。 Put 如果放入的值为空，直接return. 检查当前goroutine的是否设置对象池私有值，如果没有则将x赋值给其私有成员，并将x设置为nil。 如果当前goroutine私有值已经被设置，那么将该值追加到共享列表。</description></item><item><title>B Tree</title><link>https://sdttttt.github.io/blog/btree/</link><pubDate>Sun, 30 Aug 2020 20:41:54 +0800</pubDate><guid>https://sdttttt.github.io/blog/btree/</guid><description>这篇文章以数据库存储的数据结构来引出本文的重点B树,以及后面还有另一种数据结构B+树.
试想, 如果你想持久化大量的数据在硬盘上, 同时还希望能高效的查询和修改他们, 你会怎么做, 使用哪种数据结构.
数组和链表, 他们的缺点很明显, 我们寻找数据需要遍历整个数据结构, 试想一下你的数据库中有50PB的数据, 这个开销是我们无法接受的.
哈希表, 通过给定的数据通过Hash函数生成对应的索引, 能非常高效的找到对应的数据. 但是, 哈希表不能用于范围查询.
二叉树, 一种使用二分法作为查询算法的数据结构, 在内存中, 二叉树的效率确实非常高, 但是如果是在硬盘上, 每次读取节点, 都需要进行一次IO, 随着数据量的增大, 深度逐渐加深, 二叉树的效率就会大大降低.
B Tree B树存在一些和二叉树不一样的地方: 二叉树每个节点只保存一份数据以及两个指针, B树在每个节点都可以保留一样数量的数据和指针, 指针的数量为数据的数量+1.
在B树中还有存在一个概念, 阶数, 它决定了该B树每个节点应该有多少数据以及指针.
Rules 排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；例如一个节点能存放3份数据, 该数据需要从左到右增序存放, 1, 2, 3.
子节点数：非叶节点的子节点数&amp;gt;1，且&amp;lt;=M ，且M&amp;gt;=2，空树除外(注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉)；
关键字数：子节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个(注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);
所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;
Find 我们用一个图和一个实际的例子来理解B树(这里为了理解方便我就直接用实际字母的大小来排列C&amp;gt;B&amp;gt;A):
如上图我要从上图中找到E字母，查找流程如下:
获取根节点的关键字进行比较，当前根节点关键字为M，E&amp;lt;M(26个字母顺序)，所以往找到指向左边的子节点(二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点)；
拿到关键字D和G，D&amp;lt;E&amp;lt;G 所以直接找到D和G中间的节点；
拿到E和F，因为E=E 所以直接返回关键字和指针信息(如果树结构里面没有包含所要查找的节点则返回null).</description></item><item><title>Blog Upgrade</title><link>https://sdttttt.github.io/blog/blogupgrade/</link><pubDate>Sat, 29 Aug 2020 18:07:48 +0800</pubDate><guid>https://sdttttt.github.io/blog/blogupgrade/</guid><description>这几天修改了这个Blog的主题, 加载速度应该是更快了, 而且优化了整个项目的自动部署. 取消了双仓库的部署策略, 在部署任务的执行上也用上了异步.
现在每次修改完成后的生成以及部署的速度比以前快了大概40%左右.但是访问Github Page的速度还是一如既往的的满.</description></item><item><title>Thread Pool Executor 运行细节</title><link>https://sdttttt.github.io/blog/thread_pool_executor/</link><pubDate>Tue, 25 Aug 2020 17:29:15 +0800</pubDate><guid>https://sdttttt.github.io/blog/thread_pool_executor/</guid><description>先说说线程池本身, 由于线程资源本身在计算机中比较昂贵, 创建和销毁都有相当的开销, 所以在一些处理简单但是并发量大的场景使用一个请求对应一个线程的是不明智的选择.
ThreadPoolExecutor是Java中线程池的一种实现. 构造函数如下:
public ThreadPoolExecutor(int corePoolSize, // 核心线程数量 int maximumPoolSize, // 最大线程数量 long keepAliveTime, // 存活时间 TimeUnit unit, // 时间单位 BlockingQueue&amp;lt;Runnable&amp;gt; workQueue // 来个列队 ) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } 提交任务时的运行如下:
如果正在运行的线程数 &amp;lt; coreSize，马上创建线程执行该task，不排队等待； 如果正在运行的线程数 &amp;gt;= coreSize，把该task放入阻塞队列； 如果队列已满 &amp;amp;&amp;amp; 正在运行的线程数 &amp;lt; maximumPoolSize，创建新的线程执行该task； 如果队列已满 &amp;amp;&amp;amp; 正在运行的线程数 &amp;gt;= maximumPoolSize，线程池调用handler的reject方法拒绝本次提交。 从worker线程自己的角度来看，当worker的task执行结束之后，循环从阻塞队列中取出任务执行。</description></item><item><title>Raft实现的思考</title><link>https://sdttttt.github.io/blog/raft_impl/</link><pubDate>Thu, 25 Jun 2020 19:02:23 +0800</pubDate><guid>https://sdttttt.github.io/blog/raft_impl/</guid><description>比较Raft算法和Paxos算法之后,确实能感受到Raft算法更加接近正常人的思维逻辑, Paxos反而比较专业?
本文会说一些Raft算法实现上的一些考量, 我目前还没有正式开始开发Raft的实现. 文中所有的内容仅供参考.
Raft最基础分为三种状态: Leader, Follower, Candidate. 整个Raft主体即是一个状态机.
每个RaftNode都需要处理外部的事件.所以我们可以采用事件驱动模型.
整体我们可以拆分为三个部分:
RaftProcessor: 处理事件的处理器. EventDispatcher: 负责接收外部任务,发送给Raft本体, 或者接收Raft本体发来的事件,向外发布. LogSynchronizer: 同步LogBuffer中的日志到Raft本体. 三个部分可以使用Channel来到达互相通信.</description></item><item><title>Kanon</title><link>https://sdttttt.github.io/blog/kanon/</link><pubDate>Fri, 12 Jun 2020 17:09:04 +0800</pubDate><guid>https://sdttttt.github.io/blog/kanon/</guid><description>有一段时间没有玩过GALGAME了.
所以就去尝试玩了Kanon.
总之就是, 非常后悔.</description></item><item><title>Database Storage</title><link>https://sdttttt.github.io/blog/database_storage/</link><pubDate>Tue, 02 Jun 2020 19:51:50 +0800</pubDate><guid>https://sdttttt.github.io/blog/database_storage/</guid><description>CMU Database System 15-445/645 储存 Part 1
数据库存储的数据在 FS(File System) 中是以 块(Block) 的方式表示的.
实际上你很可能已经见到过了,在MySQL中的数据库就是以一切Block文件的方式存储的.
这篇文章会告诉你目前常见的数据库存储方式.
最开始用Tuple Storage来尝试改善数据库的存储结构.
它的工作原理比较简单, 每一个Page维护一个Header, Header中会包含一些Page的元数据,以及被存储数据的偏移值.
每当插入一个Tuple,我们就会Update Header中的偏移值.
这个设计中存在比较大的问题, 如果我们删除了底下Tuple,就不得不移动所有Tuple. 如果不移动数据, 那我们也要花费高昂的代价去维护Header中Page的meta数据.
目前最常见的就是Slotted Pages的方式去存储数据. 在不同数据库中的实现细节可能不同,但是从高级层面来讲,大多数数据库系统, 用的都是这种方式去存储数据.
每个Page中有三个部分:
Header: 保存最基本的matedata, 还包含一些checksum和访问时间之类的. SlotArray: 将每一个特定的Slot映射到对应Tuple的偏移值上. TupleArray: 储存每一个Tuple. 在这个结构中Header后面紧接这SoltArray, 而Tuple是从Page的尾部开始存储的. 每个Page存储的Tuple的个数是固定的.
如果Tuple被删除,我们也只需要删除固定的Solt就行. 空出来的空间碎片,可以由数据库的空间整理功能去完成. 维护每个Tuple的成本也比较小.只需要改变Solt就可以.
最后讲一个Demo来演示数据库的工作过程.
假如我想要找一个叫A的人,我会先去查找索引. 从索引里我知道A的Page是123, Solt是2. 我去找管理Pages的人,让他把Page123的指针给我, 然后拿着Page的指针,找到Solt2中的偏移地址,找到了A这个人.</description></item><item><title>Red Black Tree</title><link>https://sdttttt.github.io/blog/red-black-tree/</link><pubDate>Mon, 25 May 2020 19:27:28 +0800</pubDate><guid>https://sdttttt.github.io/blog/red-black-tree/</guid><description>半年前在研究HashMap的时候已经学习过红黑树的规则原理了. 不过现在又遇到就忘记是怎么实现的了.(只知道这玩意是用来平衡树的) 这次就把这个数据结构做一个了断.
性质 性质1：每个节点要么是黑色，要么是红色。 性质2：根节点是黑色。 性质3：每个叶子节点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 满足这5个性质就能保证红黑树是平衡的.
Insert 插入的节点默认是红色的.因为这样可以最大限度满足红黑树的5个性质.
请试想一下.如果插入的节点是红色:
性质1可以满足. 性质2可以满足. 性质3可以满足(插入红色节点后自动衍生出2个黑色的NIL节点). 性质4可能没法满足(新插入的节点的父节点也是红色). 性质5可能没法满足(父节点是黑色时就不行). 然后是红黑树节点的左右旋.
看懂没? 节点的旋转大概就是这样。
然后就是要分插入的情况了.
第一种：根节点为空。这种情况，将node的颜色改为黑色即可.
第二种: node的父节点为黑色。这种情况不需要做修改.
第三种: node的父节点为红色 (根据性质3，N的祖父节点必为黑色). 这种情况和变换规则都比较多.下面细说&amp;hellip;
node的叔父节点为红色。这种情况，将N的父节点和叔父节点的颜色都改为黑色，若祖父节点是跟节点就将其改为黑色，否则将其颜色改为红色，并以祖父节点为插入的目标节点开始重新递归修复红黑树. node的叔父节点为黑色，且node和node的父节点在同一边 (即父节点为祖父的左儿子时，N也是父节点的左儿子。父节点为祖父节点的右儿子时。N也是父节点的右儿子)。以父节点为祖父节的左儿子为例，将父节点改为黑色，祖父节点改为红色，然后以祖父节点为基准右旋。(N为父节点右儿子时做相应的左旋) node的叔父节点为黑色，且node和node的父节点不在同一边 (即父节点为祖父的左儿子时，N是父节点的右儿子。父节点为祖父节点的右儿子时。N也是父节点左右儿子)。以父节点为祖父节点的左儿子为例。以父节点为基准，进行左旋，然后以父节点为目标插入节点进入情况3的b情况进行操作。 Delete 这个以后再说.
Search 红黑树算是搜索二叉树的一个子集，Search方法是相同的。</description></item><item><title>Tree by Rust implement</title><link>https://sdttttt.github.io/blog/tree_rust/</link><pubDate>Wed, 20 May 2020 19:14:33 +0800</pubDate><guid>https://sdttttt.github.io/blog/tree_rust/</guid><description/></item><item><title>Stack by Rust implement</title><link>https://sdttttt.github.io/blog/stack_rust/</link><pubDate>Wed, 20 May 2020 19:01:23 +0800</pubDate><guid>https://sdttttt.github.io/blog/stack_rust/</guid><description/></item><item><title>GFS</title><link>https://sdttttt.github.io/blog/gfs/</link><pubDate>Sat, 09 May 2020 13:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/gfs/</guid><description>这是 MIT 6.824 课程GFS部分的一些总结.
GFS (Google File System) 是Google为了管理海量数据而开发的一个分布式文件系统.
直接进入正题.
在GFS中文件是以Chunk的形式存储。所谓的Chunk是一个储存块。一个Chunk的大小为64MB.一个文件会分为多个Chunk.储存在不同的服务器里。当然也会有2-3份Chunk的拷贝。
GFS中还存在一个Master，Master收集所有文件的metadata, 保存在一张表中。
下面简单的解释一下读操作的交互。
Client指定的文件名和字节偏移转换成文件的一个块索引（Chunk Index）。 给Master发送一个包含文件名和块索引的请求。 master回应对应的Chunk Handle(存储数据服务器以Chunk Handle标识Chunk)和副本的位置（多个副本）。 Client以文件名和块索引为键缓存这些信息。（handle和副本的位置） Client向其中一个副本发送一个请求，很可能是最近的一个副本。请求指定了Chunk Handle和块内的一个字节区间。 除非缓存的信息不再有效（cache for a limited time）或文件被重新打开，否则以后对同一个块的读操作不再需要client和master间的交互。</description></item><item><title>一致性哈希算法</title><link>https://sdttttt.github.io/blog/consistent_hash_algorithm/</link><pubDate>Mon, 27 Apr 2020 10:05:10 +0800</pubDate><guid>https://sdttttt.github.io/blog/consistent_hash_algorithm/</guid><description>第一代分布式系统采用的是中心化的系统，对于存贮大量数据的分布式系统来说它的缺点就是中央节点成为了整个个分布式系统的单点故障.
第二代分布式系统，节点之间通行采用的是广播，每个节点都向自己相连的所有节点进行询问，被询问的节点如果不知道这个文件在哪里,就再次进行广播&amp;hellip;&amp;hellip;如此往复,直至找到所需文件。请求变多就意味着会产生广播风暴，这会严重占用带宽和系统资源。
第三代分布式系统开始采用DHT(Distrbuted Hash Table)，也就是一致性HASH算法.
算法背景 一致性 HASH 算法在 1997 年由麻省理工学院的 Karger 等人在解决分布式 Cache 中提出的,设计目标是为了 解决因特网中的热点(Hot spot)问题,初衷和 CARP 十分类似。一致性 HASH 修正了 CARP 使用的简单哈希 算法带来的问题,使得 DHT 可以在 P2P 环境中真正得到应用。
但现在一致性 hash 算法在分布式系统中也得到了广泛应用,研究过 memcached 缓存数据库的人都知道, memcached 服务器端本身不提供分布式 Cache 的一致性,而是由客户端来提供,具体在计算一致性 HASH 时采用如下步骤:
首先求出 memcached 服务器(节点)的哈希值,并将其配置到 0 ~ 2^32 的圆(continuum)上。
然后采用同样的方法求出存储数据的键的哈希值,并映射到相同的圆上。
然后从数据映射到的位置开始顺时针查找,将数据保存到找到的第一个服务器上。如果超过 2^32 仍然找不到服务器,就会保存到第一台 memcached 服务器上。
从上图的状态中添加一台 memcached 服务器。余数分布式算法由于保存键的服务器会发生巨大变化 而影响缓存的命中率,但一致性Hashing 中,只有在圆(continuum)上增加服务器的地点逆时针方向 的第一台服务器上的键会受到影响。
性质 因为考虑到整个系统的节点数量是动态的，每时每刻有新节点加入和旧节点的失效。 在这类情况下依然要保证系统的可用性，这是值得思考的，尤其是在设计分布式缓存系统的时候。 如果不采用一致性HASH算法, 客户端在计算数据的 hash 时往往要重新计算(通常这个 Hash 算法和系统中的节点数量有关), 由于 Hash 值已经改变，所以很有可能找不到在整个系统中所对应的节点，导致不可用。所以一致性HASH算法，在分布式系统中十分重要。</description></item><item><title>File Upload</title><link>https://sdttttt.github.io/blog/file_upload/</link><pubDate>Sun, 12 Apr 2020 10:46:06 +0800</pubDate><guid>https://sdttttt.github.io/blog/file_upload/</guid><description>DVWA File upload 过关秘籍.
LOW if( isset( $_POST[ &amp;#39;Upload&amp;#39; ] ) ) { // Where are we going to be writing to? $target_path = DVWA_WEB_PAGE_TO_ROOT . &amp;#34;hackable/uploads/&amp;#34;; $target_path .= basename( $_FILES[ &amp;#39;uploaded&amp;#39; ][ &amp;#39;name&amp;#39; ] ); // Can we move the file to the upload folder? // 完全没做过滤. // 上传一个PHP文件也是可以的. if( !move_uploaded_file( $_FILES[ &amp;#39;uploaded&amp;#39; ][ &amp;#39;tmp_name&amp;#39; ], $target_path ) ) { // No echo &amp;#39;&amp;lt;pre&amp;gt;Your image was not uploaded.</description></item><item><title>Sql Injection Blind</title><link>https://sdttttt.github.io/blog/sql_injection_blind/</link><pubDate>Fri, 10 Apr 2020 11:11:22 +0800</pubDate><guid>https://sdttttt.github.io/blog/sql_injection_blind/</guid><description>返回的结果集无法看到，只能通过一些页面显示或状态来判断。 像瞎子一样。
DVWA SQL Injection blind 过关秘籍.
Low if(isset( $_GET[ &amp;#39;Submit&amp;#39; ])) { // Get input $id = $_GET[ &amp;#39;id&amp;#39; ]; // Check database $getid = &amp;#34;SELECT first_name, last_name FROM users WHERE user_id = &amp;#39;$id&amp;#39;;&amp;#34;; // 没有一点点防备 // 尝试构造: (由于看不到结果集，所以脱裤子的语句是无效) // SELECT first_name, last_name FROM users WHERE user_id = &amp;#39;0&amp;#39; union select 1,2 # &amp;#39;; // User ID exists in the database. &amp;lt;存在注入漏洞&amp;gt; // SELECT first_name, last_name FROM users WHERE user_id = &amp;#39;0&amp;#39; union select 1,if(length( database())=4,sleep(4),2) # &amp;#39;; $result = mysql_query( $getid ); // Removed &amp;#39;or die&amp;#39; to suppress mysql errors // Get results $num = @mysql_numrows( $result ); // The &amp;#39;@&amp;#39; character suppresses errors if( $num &amp;gt; 0 ) { // Feedback for end user echo &amp;#39;&amp;lt;pre&amp;gt;User ID exists in the database.</description></item><item><title>SQL Injection</title><link>https://sdttttt.github.io/blog/sql_injection/</link><pubDate>Fri, 10 Apr 2020 10:54:47 +0800</pubDate><guid>https://sdttttt.github.io/blog/sql_injection/</guid><description>DVWA SQL Injection 过关秘籍.
LOW if( isset( $_REQUEST[ &amp;#39;Submit&amp;#39; ] ) ) { // Get input $id = $_REQUEST[ &amp;#39;id&amp;#39; ]; // Check database $query = &amp;#34;SELECT first_name, last_name FROM users WHERE user_id = &amp;#39;$id&amp;#39;;&amp;#34;; // 并没有做什么注入防护 // 尝试构造： // select first_name, last_name from from users where user_id = &amp;#39;1&amp;#39; and 1=1; // select first_name, last_name from from users where user_id = &amp;#39;1&amp;#39; and 1=2; // select first_name, last_name from from users where user_id = &amp;#39;1&amp;#39; or 1=1; $result = mysql_query( $query ) or die( &amp;#39;&amp;lt;pre&amp;gt;&amp;#39; .</description></item><item><title>The Framework a good design?</title><link>https://sdttttt.github.io/blog/library_and_framework/</link><pubDate>Mon, 06 Apr 2020 23:34:30 +0800</pubDate><guid>https://sdttttt.github.io/blog/library_and_framework/</guid><description>我第一次听到框架这个概念已经是在大学的时候了，当时我的老师和我提起。 一开始我非常不习惯在我不熟悉的上下文中编写程序的感觉。只能用四个字来形容寸步难行。
过了一段时间后，当你熟悉里这个框架提前为你所做的一切的时候，一切只能用四个字来形容素巴拉细（美妙）。
后来，我接触了各种形形色色的框架，从PHP到Java.
最让我惊叹的莫过于SpringBoot, 它几乎为你准备好了你所需要的一切，如果你需要其他的，也能非常容易的引入进来， 任何框架以及库都能和Spring完美的结合在一起。Spring的可扩展性是我见过所有框架中最棒的！（它的核心理念就是IOC），不得不赞叹Spring是应用层的完美产物。（Spring无法被其他语言模仿和Java的万物对象的理念有很大关系）
曾经的软件工程师没有这样的待遇，他们往往是从头构建起他们的应用。 这使得成为软件工程师这一职业难以企及。
由于如今软件行业的变化，软件工程师们已经不能仅仅只在底层工作了，应用层的发展也突飞猛进。 各种软件架构的出现应接不暇。
框架最初是为了解决重复而复杂的工作而诞生出来的产物。 帮助我们不必再写重复的代码，只需要关心业务逻辑。
框架可以说是为了应用层的软件工程师而设计的。他们往往不会关心更细粒度的工作。他们只追求稳定的应用和企业架构。
To be continued&amp;hellip;</description></item><item><title>SS:SP鸡你太美存器</title><link>https://sdttttt.github.io/blog/sssp/</link><pubDate>Mon, 06 Apr 2020 16:38:01 +0800</pubDate><guid>https://sdttttt.github.io/blog/sssp/</guid><description>如今的CPU都有提供栈机制，8086也不例外。
8086提供的最基本的两个指令就是push and pop.
push ax ;将寄存器ax中的数据送入栈顶 pop ax ;将栈顶的数据送入ax 我们知道CS:IP寄存器存放了下一条指令的段地址和偏移地址，那么CPU是如何知道栈顶在哪呐？ 显然也有两个寄存器专门存放栈顶的地址，那就是SS:SP寄存器，SS = 段地址， SP = 偏移地址
任意时刻，SS:SP都指向栈顶元素。push和pop指令执行时CPU将从SS和SP中获得栈顶的地址。
push 有2步:
SP -= 2 SS:SP指向栈顶前面的单元，以这个位置为新栈。 将AX中的内容送入 SS:SP 所指的位置. 10000H |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| 1000EH |__23___| &amp;lt;= SS:SP 1000FH |__01___| 10000H |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| &amp;lt;= SS:SP: 换个位置 |_______| 1000EH |__23___| 1000FH |__01___| 10000H |_______| |_______| |_______| |_______| |_______| |_______| |_______| |_______| ;来自ax寄存器的数据 |__54___| &amp;lt;= SS:SP: 换个位置 |__11___| 1000EH |__23___| 1000FH |__01___| 假设 10000H -&amp;gt; 1000FH 这段空间是栈，那么栈空时，SS:SP在呐？</description></item><item><title>CSIP鸡你太美存器</title><link>https://sdttttt.github.io/blog/csip/</link><pubDate>Mon, 06 Apr 2020 15:35:44 +0800</pubDate><guid>https://sdttttt.github.io/blog/csip/</guid><description>之前刚学的时候对这个玩意音响没那么深刻，现在再学，感觉很不一样了。
CS为代码段寄存器，IP为指令指针寄存器。 设CS = M, IP = N, 8086CPU将从 M × 16 + N 处读取指令并进行。
也可以这样表述： 8086CPU中，任意时刻，CPU都会将CS:IP指向的内容做为执行指令.
执行流程:
初始状态: CS = 2000H, IP = 0000H CS:IP 内容送入地址加法器，2000H × 16 + 0000H = 20000H 地址加法器计算出物理地址20000H后将结果送入输入输出电路. 输入输出电路将物理地址20000H送到地址总线。 内存将物理地址20000H上存放的机器指令X通过数据总线送入CPU. 输入输出电路将机器指令X送入指令缓冲器。 寄存器IP的值自动增加。 以此类推&amp;hellip; 当8086CPU加点或者复位后，CS = FFFFH, IP = 0000H,也就是CPU清晨起床做的第一件事就是去执行FFFF0H内存单元中存放的机器指令。
修改CS:IP mov指令能帮我们将值送入寄存器。但是，它不能用于修改CS:IP，原因很简单8086出于设计考量不允许。 能修改CS:IP的指令统称为转移指令（以后我们深入研究）,现在我学习第一个可以修改CS:IP寄存器的指令，jmp.
若想同时修改CS:IP寄存器,可以用jmp 段地址, 偏移地址的指令来完成。
jmp 2AE3:3 ;执行后: CS = 2AE3H IP = 0003H, CPU 将从这2AE33H 处读取指令 如果只想修改IP寄存器, 可以用jmp 寄存器的指令来完成.
jmp ax 类似, mov IP, ax</description></item><item><title>MultiplexingIO</title><link>https://sdttttt.github.io/blog/multiplexingio/</link><pubDate>Mon, 06 Apr 2020 12:42:26 +0800</pubDate><guid>https://sdttttt.github.io/blog/multiplexingio/</guid><description>其实“I/O多路复用”这个坑爹翻译可能是这个概念在中文里面如此难理解的原因。所谓的I/O多路 复用在英文中其实叫 I/O multiplexing. 如果你搜索multiplexing啥意思,基本上都会出这个图:
于是大部分人都直接联想到&amp;quot;一根网线,多个sock复用&amp;quot; 这个概念,包括上面的几个回答, 其实不 管你用多进程还是I/O多路复用, 网线都只有一根好伐。多个Sock复用一根网线这个功能是在内核 +驱动层实现的.
重要的事情再说一遍: I/O multiplexing 这里面的 multiplexing 指的其实是在单个线程通过记 录跟踪每一个Sock(I/O流)的状态(对应空管塔里面的Fight progress strip槽)来同时管理多个I/O 流. 发明它的原因,是尽量多的提高服务器的吞吐能力。
是不是听起来好拗口,看个图就懂了.
在同一个线程里面, 通过拨开关的方式,来同时传输多个I/O流, (学过EE的人现在可以站出来义正 严辞说这个叫“时分复用”了)。
什么,你还没有搞懂 “一个请求到来了,nginx使用epoll接收请求的过程是怎样的”, 多看看这个 图就了解了。提醒下,ngnix会有很多链接进来, epoll会把他们都监视起来,然后像拨开关一样, 谁有数据就拨向谁,然后调用相应的代码处理。
了解这个基本的概念以后,其他的就很好解释了。
select, poll, epoll 都是I/O多路复用的具体的实现,之所以有这三个鬼存在,其实是他们出现是有 先后顺序的。
I/O多路复用这个概念被提出来以后, select是第一个实现 (1983 左右在BSD里面实现的)。
select 被实现以后,很快就暴露出了很多问题。
select 会修改传入的参数数组,这个对于一个需要调用很多次的函数,是非常不友好的。 select 如果任何一个sock(I/O stream)出现了数据,select 仅仅会返回,但是并不会告诉你是那 个sock上有数据,于是你只能自己一个一个的找,10几个sock可能还好,要是几万的sock每次 select 不是线程安全的,如果你把一个sock加入到select, 然后突然另外一个线程发现,尼玛,这 个sock不用,要收回。对不起,这个select 不支持的,如果你丧心病狂的竟然关掉这个sock, select的标准行为是。。呃。。不可预测的, 这个可是写在文档中的哦. “If a file descriptor being monitored by select() is closed in another thread, the result is unspecified.</description></item><item><title>领域逻辑的组织模式</title><link>https://sdttttt.github.io/blog/domain-logic-org-mode/</link><pubDate>Fri, 03 Apr 2020 20:58:28 +0800</pubDate><guid>https://sdttttt.github.io/blog/domain-logic-org-mode/</guid><description>目前领域逻辑的组织模式分为三种，“事务脚本”，“领域模型” 以及 “表模块”。
事务脚本类似于面向过程编程，事务脚本有以下优点：
它是一种大多数软件工程师都能理解的简单过程模型。 它能和一个行数据入口或表数据入口简单的数据源很好的协作。 非常容易设定事务的边界。 一个组数据源操作便是一个独立的事务脚本。 当然事务脚本也存在很大的缺陷，当领域逻辑开始变得复杂时，这些缺点就开始暴露出来。 当几个事务要执行类似的逻辑时，通常几个脚本中会含有某些相同的代码。 通过将这些代码提取出来，来形成公共的子例程，来消除这种情况。 但是，很多时候消除副本会变得棘手，而检测副本则更困难，倒是消除副本后的程序反而比以前还要杂乱无章，难以维护。
复杂的领域逻辑，必然要引入对象，解决前面描述问题的面向对象方法就是领域模型。 一个内容管理系统会有用户，文章等类，进行鉴权，以及写入等逻辑均置于领域模型中。 因此，发布对象调用一次写入方法。 可能还会有其他例程来完成一些读取功能，但它其实都是调用领域模型中已有打方法实现的。
领域模型的控制不再是由一个过程来控制用户某一个动作的逻辑，而是由每个对象都承担一部分相关逻辑。
领域模型的开销来自于数据源的复杂度和使用上的复杂性，刚刚接触领域模型的人会需要时间来适应这种思维方式。一旦习惯了，你就会很爽！ 另一方面你需要将数据源映射到领域模型上，数据源越是复杂，领域模型的效果就越是显著。
上为事务脚本
上为领域模型
第三中为领域逻辑的组织模式为表模块，它处于事务脚本和领域模型的一个中间地带。 和领域模型最大的区别就是在表模块中一个表只对应一个实例，而领域模型一行数据便能对应一个实例。
表模块的优点在于可以很容易的和软件架构中已经存在的部分衔接，很多GUI应用都是假定将其与SQL查询结果的记录集结果协同工作的。表模块就工作在记录集之上。你可以很容易的使用。
抉择 别问，问就，直接使用领域模型。
接下来我稍微介绍一下目前各个框架/库在领域逻辑的组织模式上的选择（只列出我用）：
PHP
PHP 原生 &amp;lt;事务脚本&amp;gt; ThinkPHP &amp;lt;领域模型&amp;gt; Laravel &amp;lt;领域模型&amp;gt; YII &amp;lt;领域模型&amp;gt; Java
java.sql.* &amp;lt;事务脚本&amp;gt; MyBatis &amp;lt;表模块&amp;gt; JPA &amp;lt;领域模型&amp;gt; Go
gorm &amp;lt;表模块 | 领域模型&amp;gt; （这个比较神奇） 现在用表模块的人普遍比较多，我曾遇到好几个J2EE工程师都并不喜欢JPA的思维模式。</description></item><item><title>About the Blog</title><link>https://sdttttt.github.io/blog/about_blog/</link><pubDate>Fri, 03 Apr 2020 15:36:02 +0800</pubDate><guid>https://sdttttt.github.io/blog/about_blog/</guid><description>blog里的文章并非全部原创，有一部分是经过修改后整理出要点，集中一起写到这里面。也包涵了一些我对整个软件行业的想法。
这个blog是用Hugo构建的，Theme使用的是rocinante,live2D的纸片人是我自己加的.(不是主题里自带的).
我之前还使用过Vuepress做为静态网站生成器，不过自定义程度很低，也不是很复合我的审美。（我希望是旁边不要出现目录栏）
后面我就转战Hugo,优点：用Go编写，生成快。生态圈也比较良好。我第一个使用的Theme是book，不得不说，配置复杂，我就马上丢弃了，后面又使用了Ezhi，由于我不是很喜欢红色，就又扔了。
然后就使用了现在这个Theme，还是比较满意的，很极简。后面也加了utteranc做为评论模块，选择utteranc的理由很简单，最初Hugo是自带Disqus做为评论模块的，但是无奈这个Disqus在国外，而且还是被墙的！
后来暂时搁了一段时间，才找到utteranc，优点就是结合Github issues无需翻墙，使用的UI也是Github的（Github使用的UI是Bootstrap库），而且零配置，授权一下App，改一下JS的tag马上就可以用。</description></item><item><title>只需要服务中心</title><link>https://sdttttt.github.io/blog/onlyhub/</link><pubDate>Thu, 02 Apr 2020 15:58:01 +0800</pubDate><guid>https://sdttttt.github.io/blog/onlyhub/</guid><description>目前，市面上以及出现了各种各样的适用于微服务(下面简称ms)的注册中心，配合其使用的还有各种ms框架，例如Alibaba的Dubbo。
微服务能通过分解服务粒度，然后针对特定服务进行性能扩展，来达到高性能的目的。
其中服务中心负责服务的注册和生命周期管理，Dubbo之类的微服务框架则对服务的注册, 负载均衡，服务鉴权, 服务调用等一系列操作做封装，供用户调用.
使得用户不用去关心微服务的实现细节。
我的想法相反，或许能让服务中心做更多的事。
我们可以从头，去设计一个服务中心：
只管理服务名和服务地址。 消费端索取服务时，则由服务中心来做负载均衡和一些额外的工作，直接给出服务提供方地址。 其他的功能可以按照现有的服务注册中心来设计。
关于微服务的调用，则由服务注册中心提供一个微服务库，来供我们调用，或者由用户自己实现。这个架构下，就不需要Dubbo之类的RPC框架。
优点：模块减少，开发可能会成本减少。
缺点：需要服务中心来提供微服务调用库。（而且服务中心处理的东西变多了，不知道性能会有多少影响）
目前小生已经搞了一个类似这中服务注册中心的Demo，可以参考。
https://github.com/sdttttt/go-tds
（这只是一个我突发的灵感罢了，其实挺荒唐的。）</description></item><item><title>Kratos 初始化流程源码解析</title><link>https://sdttttt.github.io/blog/kratos/</link><pubDate>Tue, 31 Mar 2020 20:17:28 +0800</pubDate><guid>https://sdttttt.github.io/blog/kratos/</guid><description>Kratos 是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具。
名字来源于:《战神》游戏以希腊神话为背景，讲述由凡人成为战神的奎托斯（Kratos）成为战神并展开弑神屠杀的冒险历程。
好！开始吧！
小提示：阅读源码时请保持清醒。
首先是按照Kratos tool 生产的工程目录。
├── CHANGELOG.md ├── OWNERS ├── README.md ├── api # api目录为对外保留的proto文件及生成的pb.go文件 │ ├── api.bm.go │ ├── api.pb.go # 通过go generate生成的pb.go文件 │ ├── api.proto │ └── client.go ├── cmd │ └── main.go # cmd目录为main所在 ├── configs # configs为配置文件目录 │ ├── application.toml # 应用的自定义配置文件，可能是一些业务开关如：useABtest = true │ ├── db.toml # db相关配置 │ ├── grpc.toml # grpc相关配置 │ ├── http.toml # http相关配置 │ ├── memcache.</description></item><item><title>Protubuf 原理</title><link>https://sdttttt.github.io/blog/protubuf/</link><pubDate>Mon, 30 Mar 2020 03:05:12 +0800</pubDate><guid>https://sdttttt.github.io/blog/protubuf/</guid><description>protobuf的message中有很多字段,每个字段的格式为: 修饰符 字段类型 字段名 = 域号; 在序列化时,protobuf按照TLV的格式序列化每一个字段,T即Tag,也叫Key;V是该字段对应的值v 省略。 序列化后的Value是按原样保存到字符串或者文件中,Key按照一定的转换条件保存起来,序列化后的 message中字段后面的域号与字段类型来转换。转换公式如下:
(field_number &amp;laquo; 3) | wire_type
wire_type与类型的对应关系表:
wire_type meaning 0 Vaint int32、int64、uint32、uint64、sint32、sint64、bool、enum 1 64-bit fixed、sfixed64、double 2 Length-delimi string、bytes、embedded、messages、packed repeated fields 3 Start group Groups(deprecated) 4 End group Groups(deprecated) 5 32-bit fixed32、sfixed32、float 　As you can see, each field in the message definition has a unique numbered tag.</description></item><item><title>Github Actions</title><link>https://sdttttt.github.io/blog/github_actions/</link><pubDate>Wed, 11 Mar 2020 00:50:00 +0800</pubDate><guid>https://sdttttt.github.io/blog/github_actions/</guid><description>Github Actions 上传 Releases name: release # https://help.github.com/en/articles/workflow-syntax-for-github-actions#on on: push: tags: - &amp;#39;*&amp;#39; jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v1 - name: &amp;#34;find env&amp;#34; run: |set | grep GITHUB_ | grep -v GITHUB_TOKEN zip -r pkg.zip *.md - uses: xresloader/upload-to-github-release@v1 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: file: &amp;#34;*.md;*.zip&amp;#34; tags: true draft: false prerelease: true overwrite: true verbose: true</description></item><item><title>About SDTTTTT</title><link>https://sdttttt.github.io/about/</link><pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/about/</guid><description>Hi! 俺是SDTTTTT, 一个热情好客的臭鱼烂虾开发工程师, 俺常常和网络编程打交道. 没有特别擅长的编程语言, 但不写Python和PHP. 俺最喜欢的就是免费软件了.
这个博客的构建源自俺的hugo-blog-tool-man工具. 在这个博客里记录一些知识的或者是一些心情. 它托管在github page上, 因为俺只是个穷人, 嘤嘤嘤.
如果想要联系俺，请使用 , 或者 .
根据情况俺能提供给你免费的技术能力. (仅限开源工作)
下面是俺的开黑了和Discord的服务器地址, 但是Discord用的人真的很少, 开黑在国内也不温不火, 都比较尴尬. 有兴趣就进来看看吧. (๐॔˃̶ᗜ˂̶๐॓)(๐॔˃̶ᗜ˂̶๐॓)(๐॔˃̶ᗜ˂̶๐॓)</description></item><item><title>Appveyor</title><link>https://sdttttt.github.io/blog/appveyor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/appveyor/</guid><description>Appveyor 也是一款线上 CICD 工具。
Support Contexts:
Windows (Default) Ubuntu MacOS Support Languages:
Node.js io.js Xamarin Python Ruby C++ Go Ruby version: 1.0.{build}-{branch} skip_commits: files: - &amp;#39;azure-pipelines.yml&amp;#39; - &amp;#39;README.md&amp;#39; install: - set PATH=C:\Ruby26-x64\bin;%PATH% - bundle install build: off before_test: - ruby -v - gem -v - bundle -v test_script: - rails db:migrate RAILS_ENV=test Appveyor.yml Reference # Notes: # - Minimal appveyor.yml file is an empty file. All sections are optional.</description></item><item><title>Azure Pipelines</title><link>https://sdttttt.github.io/blog/azure_pipelines/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/azure_pipelines/</guid><description>Azure Pipelines是一种云服务，可用于自动构建和测试您的代码项目并将其提供给其他用户。它几乎适用于任何语言或项目类型。
Azure Pipelines将持续集成（CI）和持续交付（CD）相结合，以持续不断地测试和构建您的代码并将其交付给任何目标。
Azure Pipelines 支持非常多的语言。
Price 如果使用公共项目，则Azure Pipelines是免费的。如果您使用私人项目，则每月可以免费运行多达1800分钟（30小时）的管道作业。了解有关基于并行作业定价的更多信息。
是不是非常的棒呢 o(////▽////)q
请遵循以下基本步骤：
配置Azure Pipelines以使用您的Git存储库。 编辑azure-pipelines.yml文件以定义构建。 将您的代码推送到版本控制存储库。此操作将启动默认触发器以构建和部署，然后监视结果。 Ruby # Ruby # Package your Ruby project. # Add steps that install rails, analyze code, save build artifacts, deploy, and more: # https://docs.microsoft.com/azure/devops/pipelines/languages/ruby trigger: branches: # 只有以下分支提交才会触发CICD include: - master - sdtttttt - CICD - depend* paths: # 只有以下文件提交时不触发CICD exclude: - README.md - appveyor.yml pool: vmImage: &amp;#39;ubuntu-18.04&amp;#39; steps: - task: UseRubyVersion@0 inputs: # 天杀的，微软提供的Ubuntu 镜像已经不支持 Ruby2.</description></item><item><title>Rails Development</title><link>https://sdttttt.github.io/blog/rails_development/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/rails_development/</guid><description>Webpacker Rails 6版本开始依赖Webpacker，在运行之前必须先安装Webpacker这玩意。
rails webpacker:install 如果需要安装前端框架，请使用yarn来安装，这样部署的时候能享受到webpacker打包便利。
production Rails 6 启动时需要一串Key作为加密的salt，key不能随意生成。 生成key时，请删除config下的credentials.enc.yml 和 master.key 文件。 然后运行
rails credentials:edit 然后Rails访问静态资源，需要使用webpacker打包编译后的资产。 运行
rails assets:precompile Rails 6 在生产环境下认为你使用 Apache 和 Nginx 缓存编译后的静态资产。如果你不使用他们，需要
# config/environments/production.rb config.public_file_server.enabled = true 记住，打包之后的js以及css统一叫application.js/css 在view页面引用时需要引用application这个名字。其他的会报错</description></item><item><title>Rails ENV</title><link>https://sdttttt.github.io/blog/ror_environment_config/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/ror_environment_config/</guid><description>Rails ENV 环境配置参考 Ruby China 社区的 Wiki
Windows 10 在 Windowns 10 的环境下和Linux上差不多，不过不需要RVM
首先在Ruby官方网站下载好安装包 之后使用RubyChina提供的Source替换Gem的Source 之后使用Gem下载 Bundler 和 Rails 创建Rails项目运行即可 有一个软件叫做 RailsInstaller 可以直接帮你省下1和3步也就是直接帮你安装好了Ruby和Rails还有Gem，bundler。 但是🙅我目前使用的Railsinstaller有点问题。他的Ruby版本是2.3，rails版本是5，rails5依赖的是 &amp;gt;= 2.4版本的ruby，这就有问题了。我也没接着用这个软件了。
在rails6中加入了Webpacker的打包工具，运行之前需要先安装webpacker不然会报错。 $ rails webpacker:install
注意在上面可能会有点问题，Gem创建Rails项目的时候会下载各种依赖，这些依赖有可能会在Windows的环境上出现问题，比如我遇到的 SQLite3,所以Ruby最好还是不要在Windowns上运行。
还有Rails 是要依赖 Yarn和 nodejs 最好是10版本以上
Development Note 花了很长时间去吧Rails和一些大前端的框架合二为一，最后以失败而告终。 Rails终究是个全栈式的Web框架，老老实实用简单的就行。
Bootstrap Configuration # =&amp;gt; 首先在 Gemfile 中加入 gem &amp;#39;bootstrap&amp;#39;, &amp;#39;~&amp;gt; 4.3.1&amp;#39; gem &amp;#39;jquery-rails&amp;#39; 之后将app\assets\stylesheets\application.css 改为 scss
删掉所有的东西包括注释
加入@import &amp;ldquo;bootstrap&amp;rdquo;;
Ruby Note Todo Error running 'requirements_debian_libs_install g++ gcc autoconf automake bison libc6-dev libffi-dev libgdbm-dev libncurses5-dev libsqlite3-dev libtool libyaml-dev make pkg-config sqlite3 zlib1g-dev libgmp-dev libreadline-dev libssl-dev', please read /home/sdttttt/.</description></item><item><title>Socks5</title><link>https://sdttttt.github.io/blog/socks5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/socks5/</guid><description>SOCKS 是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递，SOCKS 是&amp;quot;SOCKetS&amp;quot;的缩写。 SOCKS5 是 SOCKS4 的升级版，其主要多了鉴定、IPv6、UDP 支持。
SOCKS5 协议可以分为三个部分：
(1) 协议版本及认证方式 (2) 根据认证方式执行对应的认证 (3) 请求信息 （1）协议版本及认证方式 创建与 SOCKS5 服务器的 TCP 连接后客户端需要先发送请求来协议版本及认证方式，
VER NMETHODS METHODS 1 1 1-255 VER 是 SOCKS 版本，这里应该是 0x05；
NMETHODS 是 METHODS 部分的长度；
METHODS 是客户端支持的认证方式列表，每个方法占 1 字节。当前的定义是：
0x00 不需要认证 0x01 GSSAPI 0x02 用户名、密码认证 0x03 - 0x7F 由 IANA 分配（保留） 0x80 - 0xFE 为私人方法保留 0xFF 无可接受的方法 服务器回复客户端可用方法：</description></item><item><title>固定搭配</title><link>https://sdttttt.github.io/blog/gudingdapei/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sdttttt.github.io/blog/gudingdapei/</guid><description>接不定式（而不接动名词）作宾语的24个常用动词 afford to do sth. 负担得起做某事
agree to do sth. 同意做某事
arrange to do sth.安排做某事
ask to do sth. 要求做某事
beg to do sth. 请求做某事
care to do sth. 想要做某事
choose to do sth. 决定做某事
decide to do sth. 决定做某事
demand to do sth. 要求做某事
determine to do sth. 决心做某事
expect to do sth. 期待做某事
fear to do sth. 害怕做某事
help to do sth. 帮助做某事
hope to do sth. 希望做某事</description></item></channel></rss>